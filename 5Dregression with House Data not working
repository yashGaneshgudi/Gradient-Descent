

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor

# Range of x-values from 0-180
X = 180
iterations = 100

data = pd.read_csv('USA_housePrices.csv')
columns = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','price']
data = data.loc[:, columns]
features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors']
x = data.loc[:, features]
y = data.loc[:, ['price']]

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size = 0.7)# Train/Test Split

#print(x_train[features[0]][3])
print('CSV ')


# Error Function
def errorFunction(m, c, id):
    error = 0
    for i in range(X):
        error += (m * i + c - database[i][id]) ** 2
    return error / X
# Derivatives
def dm(m, c, id):
    sum = 0
    for i in range(X):
        sum += (m * i + c - database[i][id]) * i
    return 2 * sum / X
def dc(m, c, id):
    sum = 0
    for i in range(X):
        sum += m * i + c - database[i][id]
    return 2 * sum / X


# Starting m,c value
m = 1
c = 1
m2 = 1
c2 = 1
m3 = 1
c3 = 1
m4 = 1
c4 = 1
m5 = 1
c5 = 1

# Gradient Descent
for i in range(iterations):
    m = m - dm(m, c, 0) * 0.000001
    c = c - dc(m, c, 0) * 0.0001
    m2 = m2 - dm(m2, c2, 1) * 0.000001
    c2 = c2 - dc(m2, c2, 1) * 0.0001
    m3 = m3 - dm(m3, c3, 2) * 0.000001
    c3 = c3 - dc(m3, c3, 2) * 0.0001        
    m4 = m4 - dm(m4, c4, 3) * 0.000001
    c4 = c4 - dc(m4, c4, 3) * 0.0001
    m5 = m5 - dm(m5, c5, 4) * 0.000001
    c5 = c5 - dc(m5, c5, 4) * 0.0001

    
#print(' prediction ',m,'  accuracy ',(m-mStatic)/mStatic*100,)
#print(' prediction ',c,'  accuracy ',(c-cStatic)/cStatic*100,)
